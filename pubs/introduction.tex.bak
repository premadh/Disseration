\chapter{Introduction}
\markboth{Introduction}{}
\label{ch:introduction}

\begin{fquote}[Henry Nix] Data does not equal information; 
information does not equal knowledge; and, most importantly 
of all, knowledge does not equal wisdom. We have oceans of data, 
rivers of information, small puddles of knowledge, and 
the odd drop of wisdom. \fqsource{{Keynote address, AURISA, 1990}} \end{fquote} 

\section{Data Explosion}
\label{s:data}
Dictionary definition of data is a piece of information that ranges from 
the values or measurements of quantitative and qualitative variables
to description of objects or phenomenon~\cite{merriam02}. In computing 
terms, data is any digitally stored information. Throughout the history,
data was universal, and found everywhere. However, only employees generated 
data in computing terms by keying in the handwritten information. Now-a-days, 
users generate data on 
their own such, for example, social network statuses or photos, thereby increasing 
the amount of data produced. Furthermore, new machines such as automatic climatic 
conditions recorder and technology such as Large Hadron Col\-lid\-er (LHC) produce 
colossal amount of data~\cite{lynch08}. There\-fore, amount of data is increasing
in astronomical proportions and are ref\-erred to as ``Big Data'' which is a 
buzzword these days in the computing domain~\cite{lynch08,manyika11frontier}.

Production of data is such humangous that it surpasses the estimates of 
Moore's Law~\cite{moore1965}. For example, 5 exabytes (EB) (1 EB= $10^{18}$ 
bytes = 1 billion gigabytes) of data were generated from  the dawn of 
civilization until 2003. Today, we create 5EB of data every two
days~\cite{sagiroglu13}. Three properties: Volume, Velocity, and 
Variety  (often referred to by 3Vs) defines the big data. The amount 
of data volume and speed at which they arrive and leave the real 
time systems provides challenges in big data research. In addition,
variety in the collected data alos poses challenges to research in 
bigdata. Naturally, measurement technology has progressed enormously, 
and produces large volumes of data. However, one major problem
with big data is that they are often accompanied by large temporal, or
spatial dimensions (sometimes both) resulting in curse of 
dimensionality~\cite{bellman61}. 

Biology is one of the largest producer of ``Big data''
and novel computational methods are necessary to analyze 
such wealth of data to convert data to knowledge and 
wisdom~\cite{howe08}. This tremendous increase in 
biological data is impossible to interpret using visual analysis 
but requires novel computational methods for through
understanding of the biological phenomenon. The growth of
biological data has produced opportunities 
and challenges for researchers working for the development
of algorithms and analysis methods in computational domain
to be useful in biological domain.


\section{Machine Learning and Data Mining}
\label{s:mldm}

Machine Learning is a core sub--area of artificial intelligence that
intersects the discipline of computer science, and statistics to 
develop algorithms that learn from the observed data, and use 
experience to improve the performance~\cite{bishop06,hastie09,mitchell97}.
Machine learning includes myriad of statistical, probabilistic and 
optimization, and induction algorithms that are applicable in different 
tasks such as classification, regression, clustering, and pattern 
discovery. Data mining, also known as knowledge discovery, is the 
process of extracting useful information such as patterns, from 
unstructured and enormous sets of data by analyzing data from different
perspectives~\cite{hand01}.

Machine learning and data mining complement each--other and 
it is difficult to make a clear distinction. Nonetheless,
machine learning algorithms are often used in the data mining 
process. The machine learning and data mining, although a new 
discipline, has large active research community. The community
have already  developed a cohort of fascinating algorithms and 
methods to treat  the concept classes, and elegant and clever 
ways to search through  databases. Therefore, data intensive 
disciplines such as biology can generate research
questions for machine learning and data mining community.


The number of training samples are often limited and data 
dimensionality increases  considerably even in the age of 
big data. For example, in genetics, number of cancer patients 
is constant while the new technology  can measure the finer units of the 
phenomenon generating data with large dimensionality. 
The implication of increasing dimensionality is that, with a limited 
size of training samples, the performance of the algorithm
deteriorates as the number of features increases. This phenomenon
is also called Hughes phenomena, or Hughes effect~\cite{hughes68}
or more generally as a curse of dimensionality~\cite{bellman61}.


\section{Contributions of the Thesis}
\label{s:contributions}

The overall contribution of this thesis is the presentation of novel framework 
and methods for the analysis of multiresolution data within a single analysis.
The developed framework and methods analyzes and models the multiresolution 
chromosomal amplification datasets. The presented methods handles
irregular, inconsistent, and hetergenous division of regions.
%, i.e., features such 
%as the pyramid structure in image processing domain~\cite{wilson00}. 
The thesis presents different framework and methods amalgamating probabilistic 
modelling and pattern mining domain. Nevertheless, the main aim of the thesis
the development of probabilistic models for multiresolution data. 

\citepub{c1} presents deterministic data transformation methods to transform 
the multi\-resolution data to single resolution. The transformed data and the data
in the same resolutions are integrated analogous to data integration
methods. The resulting integrated data can then be modeled 
in a single resolution. Similarly, \citepub{j1} pro\-vides a computationally 
efficient method to train a series of probabilistic models, i.e., mixture models.
The trained mixture
models in the series differ in number of components but are otherwise similar
to each other thus providing effective method for model selection. 


\citepub{c2} provides a mixture modelling solution to multiresolution data
by merging of mixture components. The proposed mixture modelling solution 
initially trains mixture model in each resolution and merges the similar 
components across different resolutions to incorporate information in 
the multiple resolution. Furthermore, \citepub{c3} provides a
complete mixture model for multiresolution data. Each component of the 
mixture model represents the multiresolution structure of the data
determined from the domain ontology. The individual mixture components
are fully functional Bayesian networks. Finally, \citepub{j2} proposes
a comprehensive analysis of real--world multiresolution data blending clustering 
using mixture models, pattern mining using semantic data mining, and
visualization using banded matrices.

\section{Organization of the Thesis}
\label{s:organization}
The thesis consists of two parts: introduction and articles. 
After this introductory chapter, Chapter~\ref{ch:analysismultires} 
introduces multiresolution data with a focus on cancer genomics 
and reviews the previous work in multiresolution analysis and 
the related areas. Chapter~\ref{ch:mixmodels} describes mixture 
models and model selection in mixture models. It also 
summarizes our contribution for efficient training of mixture 
models~(\citepub{j1}). 

Chapter~\ref{ch:multiresmodel} 
forms the crux of this theis and discusses  our 
contributions in multiresolution modelling. First,  
multiresolution data is modeled using deterministic data transformation 
methods for data integration~(\citepub{c1}). Second, multiresolution 
data is modeled by merging of mixture components  in different 
resolutions. The merging of mixture components models interaction
between the different models in different data resolutions~(\citepub{c2}). 
Third, a multiresolution mixture model having multiresolution
mixture components analyzes the multiresolution data. Structure
of multiresolution components is  determined from the domain 
ontology~(\citepub{c3}). Finally, a comprehensive analysis of 
multiresolution data using three step 
methodology comprising of clustering, semantic pattern mining 
and banded matrices visualization~(\citepub{j2}).
Chapter~\ref{ch:summary} summarizes the findings, presents
the conclusions, and outlines the possible future work 
related to the topic of the thesis. 


%The contributions of 
%the dissertation can be summarized with the contributions in \citepub{c1}
%\section{Multiresolution Data}
%\label{s:multiresdata}
%Multiresolution data is generated when the same phenomena is measured 
%with differet levels of precision. 
%\section{Multiresolution Data}
%\label{s:multiresdata}
